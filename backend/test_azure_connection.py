#!/usr/bin/env python3
"""
Azure OpenAI Serviceæ¥ç¶šãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
å®Ÿè¡Œå‰ã«ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚
"""

import os
import asyncio
from dotenv import load_dotenv
from langchain_openai import AzureChatOpenAI
from langchain_core.messages import HumanMessage

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

async def test_azure_openai_connection():
    """Azure OpenAI Serviceã¨ã®æ¥ç¶šã‚’ãƒ†ã‚¹ãƒˆ"""
    
    print("=" * 50)
    print("Azure OpenAI Service æ¥ç¶šãƒ†ã‚¹ãƒˆ")
    print("=" * 50)
    
    # ç’°å¢ƒå¤‰æ•°ã®ç¢ºèª
    required_vars = {
        "AZURE_OPENAI_ENDPOINT": os.getenv("AZURE_OPENAI_ENDPOINT"),
        "AZURE_OPENAI_API_KEY": os.getenv("AZURE_OPENAI_API_KEY"),
        "AZURE_OPENAI_DEPLOYMENT_NAME": os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME"),
        "AZURE_OPENAI_API_VERSION": os.getenv("AZURE_OPENAI_API_VERSION", "2024-02-15-preview")
    }
    
    # ç’°å¢ƒå¤‰æ•°ã®ãƒã‚§ãƒƒã‚¯
    missing_vars = [k for k, v in required_vars.items() if not v]
    if missing_vars:
        print("âŒ ä»¥ä¸‹ã®ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“:")
        for var in missing_vars:
            print(f"   - {var}")
        print("\n.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return False
    
    print("âœ… ç’°å¢ƒå¤‰æ•°ã®ç¢ºèªå®Œäº†")
    print(f"   ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ: {required_vars['AZURE_OPENAI_ENDPOINT']}")
    print(f"   ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ: {required_vars['AZURE_OPENAI_DEPLOYMENT_NAME']}")
    print(f"   APIãƒãƒ¼ã‚¸ãƒ§ãƒ³: {required_vars['AZURE_OPENAI_API_VERSION']}")
    print()
    
    try:
        # Azure OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
        print("ğŸ”„ Azure OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–ä¸­...")
        llm = AzureChatOpenAI(
            azure_endpoint=required_vars["AZURE_OPENAI_ENDPOINT"],
            api_key=required_vars["AZURE_OPENAI_API_KEY"],
            azure_deployment=required_vars["AZURE_OPENAI_DEPLOYMENT_NAME"],
            api_version=required_vars["AZURE_OPENAI_API_VERSION"],
#            temperature=0.1
#            max_tokens=100
        )
        print("âœ… ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–å®Œäº†")
        print()
        
        # ãƒ†ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®é€ä¿¡
        print("ğŸ”„ ãƒ†ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ä¸­...")
        test_message = HumanMessage(content="ã“ã‚“ã«ã¡ã¯ï¼ã“ã‚Œã¯æ¥ç¶šãƒ†ã‚¹ãƒˆã§ã™ã€‚ç°¡æ½”ã«å¿œç­”ã—ã¦ãã ã•ã„ã€‚")
        response = await llm.ainvoke([test_message])
        
        print("âœ… å¿œç­”ã‚’å—ä¿¡ã—ã¾ã—ãŸ:")
        print("-" * 30)
        print(response.content)
        print("-" * 30)
        print()
        
        # ã‚¹ãƒ©ã‚¤ãƒ‰ç”Ÿæˆã®ãƒ†ã‚¹ãƒˆ
        print("ğŸ”„ ã‚¹ãƒ©ã‚¤ãƒ‰ç”Ÿæˆæ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆä¸­...")
        slide_test_prompt = """
        ä»¥ä¸‹ã®JSONå½¢å¼ã§ã€ç°¡å˜ãªãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³è¨ˆç”»ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ï¼š
        {
            "plan": [
                {"topic": "å°å…¥", "slide_type": "text_slide"},
                {"topic": "æ¯”è¼ƒ", "slide_type": "table_slide"}
            ],
            "rationale": "ãƒ†ã‚¹ãƒˆç”¨ã®æ§‹æˆ"
        }
        """
        
        slide_response = await llm.ainvoke([HumanMessage(content=slide_test_prompt)])
        print("âœ… ã‚¹ãƒ©ã‚¤ãƒ‰ç”Ÿæˆãƒ†ã‚¹ãƒˆå®Œäº†")
        print()
        
        print("=" * 50)
        print("ğŸ‰ ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼")
        print("Azure OpenAI Serviceã¯æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™ã€‚")
        print("=" * 50)
        return True
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        print("\nè€ƒãˆã‚‰ã‚Œã‚‹åŸå› :")
        print("1. APIã‚­ãƒ¼ãŒæ­£ã—ããªã„")
        print("2. ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆURLãŒæ­£ã—ããªã„")
        print("3. ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆåãŒæ­£ã—ããªã„")
        print("4. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã®å•é¡Œ")
        print("5. Azure OpenAI Serviceã®ã‚¯ã‚©ãƒ¼ã‚¿åˆ¶é™")
        return False

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    result = asyncio.run(test_azure_openai_connection())
    exit(0 if result else 1)

if __name__ == "__main__":
    main()